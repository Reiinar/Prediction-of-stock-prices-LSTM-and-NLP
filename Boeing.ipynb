{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for Boeing\n",
    "Sentiment is built upon the Reuters titles dataset.\n",
    "Historical data is taken from yahoo finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\48570\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import time\n",
    "import sys\n",
    "import time\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from io import StringIO\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping historical data from yahoo finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YahooFinanceHistory:\n",
    "    timeout = 2\n",
    "    crumb_link = 'https://finance.yahoo.com/quote/{0}/history?p={0}'\n",
    "    crumble_regex = r'CrumbStore\":{\"crumb\":\"(.*?)\"}'\n",
    "    quote_link = 'https://query1.finance.yahoo.com/v7/finance/download/{quote}?period1={dfrom}&period2={dto}&interval=1d&events=history&crumb={crumb}'\n",
    "\n",
    "    def __init__(self, symbol, days_back=7):\n",
    "        self.symbol = symbol\n",
    "        self.session = requests.Session()\n",
    "        self.dt = timedelta(days=days_back)\n",
    "\n",
    "#requesting crumb and cookie\n",
    "    def get_crumb(self):\n",
    "        response = self.session.get(self.crumb_link.format(self.symbol), timeout=self.timeout)\n",
    "        response.raise_for_status()\n",
    "        match = re.search(self.crumble_regex, response.text)\n",
    "        if not match:\n",
    "            raise ValueError('Could not get crumb from Yahoo Finance')\n",
    "        else:\n",
    "            self.crumb = match.group(1)\n",
    "\n",
    "#requesting data\n",
    "    def get_quote(self):\n",
    "        if not hasattr(self, 'crumb') or len(self.session.cookies) == 0:\n",
    "            self.get_crumb()\n",
    "        now = datetime.utcnow()\n",
    "        dateto = int(now.timestamp())\n",
    "        datefrom = int((now - self.dt).timestamp())\n",
    "        url = self.quote_link.format(quote=self.symbol, dfrom=datefrom, dto=dateto, crumb=self.crumb)\n",
    "        response = self.session.get(url)\n",
    "        response.raise_for_status()\n",
    "        return pd.read_csv(StringIO(response.text), parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting data about Boeing from 400 days back\n",
    "df_v = YahooFinanceHistory('BA', days_back=4000).get_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-06-04</td>\n",
       "      <td>48.630001</td>\n",
       "      <td>50.910000</td>\n",
       "      <td>48.570000</td>\n",
       "      <td>50.570000</td>\n",
       "      <td>38.393864</td>\n",
       "      <td>7324600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-06-05</td>\n",
       "      <td>52.160000</td>\n",
       "      <td>53.259998</td>\n",
       "      <td>52.160000</td>\n",
       "      <td>52.650002</td>\n",
       "      <td>39.973049</td>\n",
       "      <td>13724100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-06-08</td>\n",
       "      <td>52.490002</td>\n",
       "      <td>53.330002</td>\n",
       "      <td>51.130001</td>\n",
       "      <td>52.830002</td>\n",
       "      <td>40.109699</td>\n",
       "      <td>7957400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-09</td>\n",
       "      <td>53.389999</td>\n",
       "      <td>53.389999</td>\n",
       "      <td>51.310001</td>\n",
       "      <td>52.349998</td>\n",
       "      <td>39.745274</td>\n",
       "      <td>7723800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-06-10</td>\n",
       "      <td>52.820000</td>\n",
       "      <td>53.200001</td>\n",
       "      <td>51.099998</td>\n",
       "      <td>52.299999</td>\n",
       "      <td>39.707298</td>\n",
       "      <td>6556200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>130.919998</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>127.949997</td>\n",
       "      <td>128.910004</td>\n",
       "      <td>128.910004</td>\n",
       "      <td>20018600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2753</th>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>129.720001</td>\n",
       "      <td>133.119995</td>\n",
       "      <td>125.199997</td>\n",
       "      <td>125.220001</td>\n",
       "      <td>125.220001</td>\n",
       "      <td>22579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.070000</td>\n",
       "      <td>119.330002</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>26002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>118.980003</td>\n",
       "      <td>122.610001</td>\n",
       "      <td>113.889999</td>\n",
       "      <td>122.519997</td>\n",
       "      <td>122.519997</td>\n",
       "      <td>37499200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>118.330002</td>\n",
       "      <td>121.889999</td>\n",
       "      <td>117.779999</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>26739000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2757 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close   Adj Close  \\\n",
       "0    2009-06-04   48.630001   50.910000   48.570000   50.570000   38.393864   \n",
       "1    2009-06-05   52.160000   53.259998   52.160000   52.650002   39.973049   \n",
       "2    2009-06-08   52.490002   53.330002   51.130001   52.830002   40.109699   \n",
       "3    2009-06-09   53.389999   53.389999   51.310001   52.349998   39.745274   \n",
       "4    2009-06-10   52.820000   53.200001   51.099998   52.299999   39.707298   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "2752 2020-05-11  130.919998  131.000000  127.949997  128.910004  128.910004   \n",
       "2753 2020-05-12  129.720001  133.119995  125.199997  125.220001  125.220001   \n",
       "2754 2020-05-13  125.000000  125.070000  119.330002  121.500000  121.500000   \n",
       "2755 2020-05-14  118.980003  122.610001  113.889999  122.519997  122.519997   \n",
       "2756 2020-05-15  118.330002  121.889999  117.779999  120.000000  120.000000   \n",
       "\n",
       "        Volume  \n",
       "0      7324600  \n",
       "1     13724100  \n",
       "2      7957400  \n",
       "3      7723800  \n",
       "4      6556200  \n",
       "...        ...  \n",
       "2752  20018600  \n",
       "2753  22579000  \n",
       "2754  26002000  \n",
       "2755  37499200  \n",
       "2756  26739000  \n",
       "\n",
       "[2757 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting dates from the latest to earliest\n",
    "df_v.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         datetime64[ns]\n",
       "Open                float64\n",
       "High                float64\n",
       "Low                 float64\n",
       "Close               float64\n",
       "Adj Close           float64\n",
       "Volume                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-06-04</td>\n",
       "      <td>48.630001</td>\n",
       "      <td>50.910000</td>\n",
       "      <td>48.570000</td>\n",
       "      <td>50.570000</td>\n",
       "      <td>38.393864</td>\n",
       "      <td>7324600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-06-05</td>\n",
       "      <td>52.160000</td>\n",
       "      <td>53.259998</td>\n",
       "      <td>52.160000</td>\n",
       "      <td>52.650002</td>\n",
       "      <td>39.973049</td>\n",
       "      <td>13724100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-06-08</td>\n",
       "      <td>52.490002</td>\n",
       "      <td>53.330002</td>\n",
       "      <td>51.130001</td>\n",
       "      <td>52.830002</td>\n",
       "      <td>40.109699</td>\n",
       "      <td>7957400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-09</td>\n",
       "      <td>53.389999</td>\n",
       "      <td>53.389999</td>\n",
       "      <td>51.310001</td>\n",
       "      <td>52.349998</td>\n",
       "      <td>39.745274</td>\n",
       "      <td>7723800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-06-10</td>\n",
       "      <td>52.820000</td>\n",
       "      <td>53.200001</td>\n",
       "      <td>51.099998</td>\n",
       "      <td>52.299999</td>\n",
       "      <td>39.707298</td>\n",
       "      <td>6556200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>130.919998</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>127.949997</td>\n",
       "      <td>128.910004</td>\n",
       "      <td>128.910004</td>\n",
       "      <td>20018600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2753</th>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>129.720001</td>\n",
       "      <td>133.119995</td>\n",
       "      <td>125.199997</td>\n",
       "      <td>125.220001</td>\n",
       "      <td>125.220001</td>\n",
       "      <td>22579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.070000</td>\n",
       "      <td>119.330002</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>26002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>118.980003</td>\n",
       "      <td>122.610001</td>\n",
       "      <td>113.889999</td>\n",
       "      <td>122.519997</td>\n",
       "      <td>122.519997</td>\n",
       "      <td>37499200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>118.330002</td>\n",
       "      <td>121.889999</td>\n",
       "      <td>117.779999</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>26739000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2757 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close   Adj Close  \\\n",
       "0    2009-06-04   48.630001   50.910000   48.570000   50.570000   38.393864   \n",
       "1    2009-06-05   52.160000   53.259998   52.160000   52.650002   39.973049   \n",
       "2    2009-06-08   52.490002   53.330002   51.130001   52.830002   40.109699   \n",
       "3    2009-06-09   53.389999   53.389999   51.310001   52.349998   39.745274   \n",
       "4    2009-06-10   52.820000   53.200001   51.099998   52.299999   39.707298   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "2752 2020-05-11  130.919998  131.000000  127.949997  128.910004  128.910004   \n",
       "2753 2020-05-12  129.720001  133.119995  125.199997  125.220001  125.220001   \n",
       "2754 2020-05-13  125.000000  125.070000  119.330002  121.500000  121.500000   \n",
       "2755 2020-05-14  118.980003  122.610001  113.889999  122.519997  122.519997   \n",
       "2756 2020-05-15  118.330002  121.889999  117.779999  120.000000  120.000000   \n",
       "\n",
       "        Volume  \n",
       "0      7324600  \n",
       "1     13724100  \n",
       "2      7957400  \n",
       "3      7723800  \n",
       "4      6556200  \n",
       "...        ...  \n",
       "2752  20018600  \n",
       "2753  22579000  \n",
       "2754  26002000  \n",
       "2755  37499200  \n",
       "2756  26739000  \n",
       "\n",
       "[2757 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment for all the articles with \"Microsoft\" in the body of an article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploading file\n",
    "df2 = pd.read_csv('df_BA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>compound_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>-0.493900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-07-07</td>\n",
       "      <td>0.074200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-07-08</td>\n",
       "      <td>0.084700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-07-09</td>\n",
       "      <td>0.153100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-07-10</td>\n",
       "      <td>0.055833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>1528</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>0.055833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>1529</td>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>-0.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>1530</td>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>0.055833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>1531</td>\n",
       "      <td>2017-02-13</td>\n",
       "      <td>-0.361200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>1532</td>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>0.055833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1533 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        Date  compound_mean\n",
       "0              0  2011-07-06      -0.493900\n",
       "1              1  2011-07-07       0.074200\n",
       "2              2  2011-07-08       0.084700\n",
       "3              3  2011-07-09       0.153100\n",
       "4              4  2011-07-10       0.055833\n",
       "...          ...         ...            ...\n",
       "1528        1528  2017-02-06       0.055833\n",
       "1529        1529  2017-02-07      -0.273000\n",
       "1530        1530  2017-02-10       0.055833\n",
       "1531        1531  2017-02-13      -0.361200\n",
       "1532        1532  2017-02-14       0.055833\n",
       "\n",
       "[1533 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting column Unnamed\n",
    "df2 = df2.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>compound_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>-0.493900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-07-07</td>\n",
       "      <td>0.074200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-07-08</td>\n",
       "      <td>0.084700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-07-09</td>\n",
       "      <td>0.153100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-07-10</td>\n",
       "      <td>0.055833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>0.055833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>-0.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>0.055833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>2017-02-13</td>\n",
       "      <td>-0.361200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>0.055833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1533 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  compound_mean\n",
       "0     2011-07-06      -0.493900\n",
       "1     2011-07-07       0.074200\n",
       "2     2011-07-08       0.084700\n",
       "3     2011-07-09       0.153100\n",
       "4     2011-07-10       0.055833\n",
       "...          ...            ...\n",
       "1528  2017-02-06       0.055833\n",
       "1529  2017-02-07      -0.273000\n",
       "1530  2017-02-10       0.055833\n",
       "1531  2017-02-13      -0.361200\n",
       "1532  2017-02-14       0.055833\n",
       "\n",
       "[1533 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date              object\n",
       "compound_mean    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing column Date type to datetime type\n",
    "df2.Date=pd.to_datetime(df2['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging dataframe with historical data with dataframe with sentiments \n",
    "df3 = pd.merge(df_v,df2,on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>compound_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>74.129997</td>\n",
       "      <td>75.160004</td>\n",
       "      <td>74.010002</td>\n",
       "      <td>74.739998</td>\n",
       "      <td>59.897026</td>\n",
       "      <td>3757800</td>\n",
       "      <td>-0.493900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-07-07</td>\n",
       "      <td>75.330002</td>\n",
       "      <td>76.199997</td>\n",
       "      <td>74.849998</td>\n",
       "      <td>75.989998</td>\n",
       "      <td>60.898773</td>\n",
       "      <td>4976900</td>\n",
       "      <td>0.074200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-07-08</td>\n",
       "      <td>75.580002</td>\n",
       "      <td>75.580002</td>\n",
       "      <td>74.570000</td>\n",
       "      <td>75.070000</td>\n",
       "      <td>60.161488</td>\n",
       "      <td>4051200</td>\n",
       "      <td>0.084700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-07-11</td>\n",
       "      <td>74.169998</td>\n",
       "      <td>74.730003</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>73.349998</td>\n",
       "      <td>58.783066</td>\n",
       "      <td>4379000</td>\n",
       "      <td>-0.157993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-07-12</td>\n",
       "      <td>73.620003</td>\n",
       "      <td>73.860001</td>\n",
       "      <td>71.790001</td>\n",
       "      <td>71.930000</td>\n",
       "      <td>57.645065</td>\n",
       "      <td>5773000</td>\n",
       "      <td>0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>162.419998</td>\n",
       "      <td>164.080002</td>\n",
       "      <td>162.380005</td>\n",
       "      <td>163.979996</td>\n",
       "      <td>152.032944</td>\n",
       "      <td>3110500</td>\n",
       "      <td>0.055833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>167.419998</td>\n",
       "      <td>164.869995</td>\n",
       "      <td>166.500000</td>\n",
       "      <td>154.369339</td>\n",
       "      <td>4243200</td>\n",
       "      <td>-0.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>165.250000</td>\n",
       "      <td>166.449997</td>\n",
       "      <td>164.470001</td>\n",
       "      <td>166.229996</td>\n",
       "      <td>155.444748</td>\n",
       "      <td>2689700</td>\n",
       "      <td>0.055833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>2017-02-13</td>\n",
       "      <td>166.449997</td>\n",
       "      <td>169.070007</td>\n",
       "      <td>166.350006</td>\n",
       "      <td>168.029999</td>\n",
       "      <td>157.127945</td>\n",
       "      <td>3765000</td>\n",
       "      <td>-0.361200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>167.699997</td>\n",
       "      <td>168.800003</td>\n",
       "      <td>167.220001</td>\n",
       "      <td>168.500000</td>\n",
       "      <td>157.567429</td>\n",
       "      <td>2580300</td>\n",
       "      <td>0.055833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1277 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close   Adj Close  \\\n",
       "0    2011-07-06   74.129997   75.160004   74.010002   74.739998   59.897026   \n",
       "1    2011-07-07   75.330002   76.199997   74.849998   75.989998   60.898773   \n",
       "2    2011-07-08   75.580002   75.580002   74.570000   75.070000   60.161488   \n",
       "3    2011-07-11   74.169998   74.730003   73.000000   73.349998   58.783066   \n",
       "4    2011-07-12   73.620003   73.860001   71.790001   71.930000   57.645065   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "1272 2017-02-06  162.419998  164.080002  162.380005  163.979996  152.032944   \n",
       "1273 2017-02-07  165.000000  167.419998  164.869995  166.500000  154.369339   \n",
       "1274 2017-02-10  165.250000  166.449997  164.470001  166.229996  155.444748   \n",
       "1275 2017-02-13  166.449997  169.070007  166.350006  168.029999  157.127945   \n",
       "1276 2017-02-14  167.699997  168.800003  167.220001  168.500000  157.567429   \n",
       "\n",
       "       Volume  compound_mean  \n",
       "0     3757800      -0.493900  \n",
       "1     4976900       0.074200  \n",
       "2     4051200       0.084700  \n",
       "3     4379000      -0.157993  \n",
       "4     5773000       0.360000  \n",
       "...       ...            ...  \n",
       "1272  3110500       0.055833  \n",
       "1273  4243200      -0.273000  \n",
       "1274  2689700       0.055833  \n",
       "1275  3765000      -0.361200  \n",
       "1276  2580300       0.055833  \n",
       "\n",
       "[1277 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning for prediction of label for the next day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deepcopying dataframe, so there would be no need to run everything from the beggining\n",
    "df = copy.deepcopy(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label indicates wheter the price will go up(1) or down(0) next day\n",
    "def add_label(dfi):\n",
    "    idx = len(dfi.columns)\n",
    "    new_col = np.where(dfi['Close'] >= dfi['Close'].shift(1), 1, 0)  \n",
    "    dfi.insert(loc=idx, column='Label', value=new_col)\n",
    "    dfi = dfi.fillna(0)\n",
    "    df['Label'] =  df['Label'].shift(-1, axis = 0)\n",
    "    df.drop(df.index[len(df)-1], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_label(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>compound_mean</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>74.129997</td>\n",
       "      <td>75.160004</td>\n",
       "      <td>74.010002</td>\n",
       "      <td>74.739998</td>\n",
       "      <td>59.897026</td>\n",
       "      <td>3757800</td>\n",
       "      <td>-0.493900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-07-07</td>\n",
       "      <td>75.330002</td>\n",
       "      <td>76.199997</td>\n",
       "      <td>74.849998</td>\n",
       "      <td>75.989998</td>\n",
       "      <td>60.898773</td>\n",
       "      <td>4976900</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-07-08</td>\n",
       "      <td>75.580002</td>\n",
       "      <td>75.580002</td>\n",
       "      <td>74.570000</td>\n",
       "      <td>75.070000</td>\n",
       "      <td>60.161488</td>\n",
       "      <td>4051200</td>\n",
       "      <td>0.084700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-07-11</td>\n",
       "      <td>74.169998</td>\n",
       "      <td>74.730003</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>73.349998</td>\n",
       "      <td>58.783066</td>\n",
       "      <td>4379000</td>\n",
       "      <td>-0.157993</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-07-12</td>\n",
       "      <td>73.620003</td>\n",
       "      <td>73.860001</td>\n",
       "      <td>71.790001</td>\n",
       "      <td>71.930000</td>\n",
       "      <td>57.645065</td>\n",
       "      <td>5773000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>162.990005</td>\n",
       "      <td>163.559998</td>\n",
       "      <td>162.309998</td>\n",
       "      <td>162.399994</td>\n",
       "      <td>150.568100</td>\n",
       "      <td>2981700</td>\n",
       "      <td>0.055833</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>162.419998</td>\n",
       "      <td>164.080002</td>\n",
       "      <td>162.380005</td>\n",
       "      <td>163.979996</td>\n",
       "      <td>152.032944</td>\n",
       "      <td>3110500</td>\n",
       "      <td>0.055833</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>167.419998</td>\n",
       "      <td>164.869995</td>\n",
       "      <td>166.500000</td>\n",
       "      <td>154.369339</td>\n",
       "      <td>4243200</td>\n",
       "      <td>-0.273000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>165.250000</td>\n",
       "      <td>166.449997</td>\n",
       "      <td>164.470001</td>\n",
       "      <td>166.229996</td>\n",
       "      <td>155.444748</td>\n",
       "      <td>2689700</td>\n",
       "      <td>0.055833</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>2017-02-13</td>\n",
       "      <td>166.449997</td>\n",
       "      <td>169.070007</td>\n",
       "      <td>166.350006</td>\n",
       "      <td>168.029999</td>\n",
       "      <td>157.127945</td>\n",
       "      <td>3765000</td>\n",
       "      <td>-0.361200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1276 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close   Adj Close  \\\n",
       "0    2011-07-06   74.129997   75.160004   74.010002   74.739998   59.897026   \n",
       "1    2011-07-07   75.330002   76.199997   74.849998   75.989998   60.898773   \n",
       "2    2011-07-08   75.580002   75.580002   74.570000   75.070000   60.161488   \n",
       "3    2011-07-11   74.169998   74.730003   73.000000   73.349998   58.783066   \n",
       "4    2011-07-12   73.620003   73.860001   71.790001   71.930000   57.645065   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "1271 2017-02-03  162.990005  163.559998  162.309998  162.399994  150.568100   \n",
       "1272 2017-02-06  162.419998  164.080002  162.380005  163.979996  152.032944   \n",
       "1273 2017-02-07  165.000000  167.419998  164.869995  166.500000  154.369339   \n",
       "1274 2017-02-10  165.250000  166.449997  164.470001  166.229996  155.444748   \n",
       "1275 2017-02-13  166.449997  169.070007  166.350006  168.029999  157.127945   \n",
       "\n",
       "       Volume  compound_mean  Label  \n",
       "0     3757800      -0.493900    1.0  \n",
       "1     4976900       0.074200    0.0  \n",
       "2     4051200       0.084700    0.0  \n",
       "3     4379000      -0.157993    0.0  \n",
       "4     5773000       0.360000    1.0  \n",
       "...       ...            ...    ...  \n",
       "1271  2981700       0.055833    1.0  \n",
       "1272  3110500       0.055833    1.0  \n",
       "1273  4243200      -0.273000    0.0  \n",
       "1274  2689700       0.055833    1.0  \n",
       "1275  3765000      -0.361200    1.0  \n",
       "\n",
       "[1276 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             datetime64[ns]\n",
       "Open                    float64\n",
       "High                    float64\n",
       "Low                     float64\n",
       "Close                   float64\n",
       "Adj Close               float64\n",
       "Volume                    int64\n",
       "compound_mean           float64\n",
       "Label                   float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training and testing datasets\n",
    "X = array[:,1:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardising features, fitting and transforming X\n",
    "X = sklearn.preprocessing.MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#casting Y to data type integer\n",
    "Y = Y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15129418 0.14381154 0.16181233 0.15513382 0.12252169 0.06436869\n",
      " 0.1636901 ]\n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'compound_mean'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(df.columns[1:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05  0.05  0.047 0.046 0.017 0.085 0.235]\n",
      "[[0.151 0.144 0.162 0.064 0.164]\n",
      " [0.162 0.153 0.169 0.092 0.521]\n",
      " [0.165 0.148 0.167 0.071 0.528]\n",
      " [0.152 0.14  0.153 0.079 0.375]\n",
      " [0.147 0.132 0.142 0.111 0.701]]\n"
     ]
    }
   ],
   "source": [
    "#choosing best features for the model\n",
    "test = SelectKBest(score_func=chi2, k=5)\n",
    "fit = test.fit(X, Y)\n",
    "np.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.151, 0.144, 0.162, 0.064, 0.164],\n",
       "       [0.162, 0.153, 0.169, 0.092, 0.521],\n",
       "       [0.165, 0.148, 0.167, 0.071, 0.528],\n",
       "       ...,\n",
       "       [0.979, 0.977, 0.979, 0.076, 0.303],\n",
       "       [0.982, 0.968, 0.975, 0.04 , 0.509],\n",
       "       [0.993, 0.992, 0.992, 0.065, 0.247]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Open, High, Low, Volume and compound mean give the most information\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\48570\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\48570\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\48570\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 957 samples, validate on 319 samples\n",
      "Epoch 1/100\n",
      "957/957 [==============================] - 1s 748us/step - loss: 0.6983 - accuracy: 0.5005 - val_loss: 0.6973 - val_accuracy: 0.4514\n",
      "Epoch 2/100\n",
      "957/957 [==============================] - 0s 187us/step - loss: 0.6965 - accuracy: 0.4974 - val_loss: 0.6893 - val_accuracy: 0.5486\n",
      "Epoch 3/100\n",
      "957/957 [==============================] - 0s 192us/step - loss: 0.6962 - accuracy: 0.4922 - val_loss: 0.6900 - val_accuracy: 0.5486\n",
      "Epoch 4/100\n",
      "957/957 [==============================] - 0s 191us/step - loss: 0.6937 - accuracy: 0.5016 - val_loss: 0.6896 - val_accuracy: 0.5486\n",
      "Epoch 5/100\n",
      "957/957 [==============================] - 0s 192us/step - loss: 0.6909 - accuracy: 0.5246 - val_loss: 0.6894 - val_accuracy: 0.5486\n",
      "Epoch 6/100\n",
      "957/957 [==============================] - 0s 194us/step - loss: 0.6953 - accuracy: 0.4963 - val_loss: 0.6896 - val_accuracy: 0.5486\n",
      "Epoch 7/100\n",
      "957/957 [==============================] - 0s 173us/step - loss: 0.6923 - accuracy: 0.5183 - val_loss: 0.6899 - val_accuracy: 0.5486\n",
      "Epoch 8/100\n",
      "957/957 [==============================] - 0s 167us/step - loss: 0.6936 - accuracy: 0.5235 - val_loss: 0.6896 - val_accuracy: 0.5486\n",
      "Epoch 9/100\n",
      "957/957 [==============================] - 0s 175us/step - loss: 0.6921 - accuracy: 0.5162 - val_loss: 0.6901 - val_accuracy: 0.5486\n",
      "Epoch 10/100\n",
      "957/957 [==============================] - 0s 178us/step - loss: 0.6935 - accuracy: 0.5152 - val_loss: 0.6896 - val_accuracy: 0.5486\n",
      "Epoch 11/100\n",
      "957/957 [==============================] - 0s 168us/step - loss: 0.6920 - accuracy: 0.5277 - val_loss: 0.6895 - val_accuracy: 0.5486\n",
      "Epoch 12/100\n",
      "957/957 [==============================] - 0s 174us/step - loss: 0.6920 - accuracy: 0.5214 - val_loss: 0.6908 - val_accuracy: 0.5486\n",
      "Epoch 13/100\n",
      "957/957 [==============================] - 0s 168us/step - loss: 0.6912 - accuracy: 0.5172 - val_loss: 0.6902 - val_accuracy: 0.5486\n",
      "Epoch 14/100\n",
      "957/957 [==============================] - 0s 168us/step - loss: 0.6924 - accuracy: 0.5225 - val_loss: 0.6918 - val_accuracy: 0.5392\n",
      "Epoch 15/100\n",
      "957/957 [==============================] - 0s 168us/step - loss: 0.6920 - accuracy: 0.5026 - val_loss: 0.6917 - val_accuracy: 0.5486\n",
      "Epoch 16/100\n",
      "957/957 [==============================] - 0s 166us/step - loss: 0.6924 - accuracy: 0.5235 - val_loss: 0.6906 - val_accuracy: 0.5486\n",
      "Epoch 17/100\n",
      "957/957 [==============================] - 0s 165us/step - loss: 0.6918 - accuracy: 0.5089 - val_loss: 0.6920 - val_accuracy: 0.5486\n",
      "Epoch 18/100\n",
      "957/957 [==============================] - 0s 169us/step - loss: 0.6908 - accuracy: 0.5235 - val_loss: 0.6916 - val_accuracy: 0.5486\n",
      "Epoch 19/100\n",
      "957/957 [==============================] - 0s 165us/step - loss: 0.6891 - accuracy: 0.5204 - val_loss: 0.6940 - val_accuracy: 0.5486\n",
      "Epoch 20/100\n",
      "957/957 [==============================] - 0s 169us/step - loss: 0.6911 - accuracy: 0.5183 - val_loss: 0.6937 - val_accuracy: 0.5486\n",
      "Epoch 21/100\n",
      "957/957 [==============================] - 0s 168us/step - loss: 0.6903 - accuracy: 0.5266 - val_loss: 0.6929 - val_accuracy: 0.5486\n",
      "Epoch 22/100\n",
      "957/957 [==============================] - 0s 168us/step - loss: 0.6877 - accuracy: 0.5193 - val_loss: 0.6948 - val_accuracy: 0.5486\n",
      "Epoch 23/100\n",
      "957/957 [==============================] - 0s 168us/step - loss: 0.6896 - accuracy: 0.4963 - val_loss: 0.6965 - val_accuracy: 0.4545\n",
      "Epoch 24/100\n",
      "957/957 [==============================] - 0s 171us/step - loss: 0.6915 - accuracy: 0.4859 - val_loss: 0.6957 - val_accuracy: 0.5486\n",
      "Epoch 25/100\n",
      "957/957 [==============================] - 0s 173us/step - loss: 0.6897 - accuracy: 0.5225 - val_loss: 0.6954 - val_accuracy: 0.5486\n",
      "Epoch 26/100\n",
      "957/957 [==============================] - 0s 170us/step - loss: 0.6862 - accuracy: 0.5329 - val_loss: 0.6977 - val_accuracy: 0.5486\n",
      "Epoch 27/100\n",
      "957/957 [==============================] - 0s 169us/step - loss: 0.6904 - accuracy: 0.5099 - val_loss: 0.6965 - val_accuracy: 0.5486\n",
      "Epoch 28/100\n",
      "957/957 [==============================] - 0s 174us/step - loss: 0.6886 - accuracy: 0.5287 - val_loss: 0.6986 - val_accuracy: 0.5486\n",
      "Epoch 29/100\n",
      "957/957 [==============================] - 0s 169us/step - loss: 0.6880 - accuracy: 0.5287 - val_loss: 0.7007 - val_accuracy: 0.5486\n",
      "Epoch 30/100\n",
      "957/957 [==============================] - 0s 171us/step - loss: 0.6916 - accuracy: 0.5152 - val_loss: 0.6970 - val_accuracy: 0.5486\n",
      "Epoch 31/100\n",
      "957/957 [==============================] - 0s 168us/step - loss: 0.6880 - accuracy: 0.5193 - val_loss: 0.6984 - val_accuracy: 0.5486\n",
      "Epoch 32/100\n",
      "957/957 [==============================] - 0s 169us/step - loss: 0.6881 - accuracy: 0.5172 - val_loss: 0.6982 - val_accuracy: 0.5486\n",
      "Epoch 33/100\n",
      "957/957 [==============================] - 0s 170us/step - loss: 0.6887 - accuracy: 0.5235 - val_loss: 0.7018 - val_accuracy: 0.5486\n",
      "Epoch 34/100\n",
      "957/957 [==============================] - 0s 170us/step - loss: 0.6860 - accuracy: 0.5225 - val_loss: 0.7015 - val_accuracy: 0.5486\n",
      "Epoch 35/100\n",
      "957/957 [==============================] - 0s 169us/step - loss: 0.6877 - accuracy: 0.5204 - val_loss: 0.7018 - val_accuracy: 0.5486\n",
      "Epoch 36/100\n",
      "957/957 [==============================] - 0s 169us/step - loss: 0.6922 - accuracy: 0.5172 - val_loss: 0.6969 - val_accuracy: 0.5486\n",
      "Epoch 37/100\n",
      "957/957 [==============================] - 0s 171us/step - loss: 0.6870 - accuracy: 0.5131 - val_loss: 0.6988 - val_accuracy: 0.5486\n",
      "Epoch 38/100\n",
      "957/957 [==============================] - 0s 171us/step - loss: 0.6874 - accuracy: 0.5057 - val_loss: 0.7004 - val_accuracy: 0.5486\n",
      "Epoch 39/100\n",
      "957/957 [==============================] - 0s 151us/step - loss: 0.6861 - accuracy: 0.5183 - val_loss: 0.7049 - val_accuracy: 0.5298\n",
      "Epoch 40/100\n",
      "957/957 [==============================] - 0s 158us/step - loss: 0.6899 - accuracy: 0.4890 - val_loss: 0.7013 - val_accuracy: 0.5486\n",
      "Epoch 41/100\n",
      "957/957 [==============================] - 0s 185us/step - loss: 0.6878 - accuracy: 0.5235 - val_loss: 0.7022 - val_accuracy: 0.5486\n",
      "Epoch 42/100\n",
      "957/957 [==============================] - 0s 170us/step - loss: 0.6908 - accuracy: 0.5068 - val_loss: 0.6996 - val_accuracy: 0.5455\n",
      "Epoch 43/100\n",
      "957/957 [==============================] - 0s 170us/step - loss: 0.6865 - accuracy: 0.5183 - val_loss: 0.7021 - val_accuracy: 0.5486\n",
      "Epoch 44/100\n",
      "957/957 [==============================] - 0s 172us/step - loss: 0.6872 - accuracy: 0.5204 - val_loss: 0.7031 - val_accuracy: 0.5486\n",
      "Epoch 45/100\n",
      "957/957 [==============================] - 0s 165us/step - loss: 0.6886 - accuracy: 0.5099 - val_loss: 0.7055 - val_accuracy: 0.5486\n",
      "Epoch 46/100\n",
      "957/957 [==============================] - 0s 170us/step - loss: 0.6896 - accuracy: 0.5277 - val_loss: 0.7011 - val_accuracy: 0.5486\n",
      "Epoch 47/100\n",
      "957/957 [==============================] - 0s 169us/step - loss: 0.6866 - accuracy: 0.5319 - val_loss: 0.7022 - val_accuracy: 0.5486\n",
      "Epoch 48/100\n",
      "957/957 [==============================] - 0s 168us/step - loss: 0.6873 - accuracy: 0.5204 - val_loss: 0.7069 - val_accuracy: 0.5486\n",
      "Epoch 49/100\n",
      "957/957 [==============================] - 0s 169us/step - loss: 0.6874 - accuracy: 0.5026 - val_loss: 0.7104 - val_accuracy: 0.5486\n",
      "Epoch 50/100\n",
      "957/957 [==============================] - 0s 170us/step - loss: 0.6907 - accuracy: 0.5141 - val_loss: 0.7013 - val_accuracy: 0.5486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "957/957 [==============================] - 0s 170us/step - loss: 0.6894 - accuracy: 0.5152 - val_loss: 0.7019 - val_accuracy: 0.5486\n",
      "Epoch 52/100\n",
      "957/957 [==============================] - 0s 167us/step - loss: 0.6876 - accuracy: 0.5266 - val_loss: 0.7059 - val_accuracy: 0.5486\n",
      "Epoch 53/100\n",
      "957/957 [==============================] - 0s 168us/step - loss: 0.6872 - accuracy: 0.5266 - val_loss: 0.7023 - val_accuracy: 0.5486\n",
      "Epoch 54/100\n",
      "957/957 [==============================] - 0s 166us/step - loss: 0.6919 - accuracy: 0.5141 - val_loss: 0.6996 - val_accuracy: 0.5486\n",
      "Epoch 55/100\n",
      "957/957 [==============================] - 0s 170us/step - loss: 0.6853 - accuracy: 0.5266 - val_loss: 0.7040 - val_accuracy: 0.5486\n",
      "Epoch 56/100\n",
      "957/957 [==============================] - 0s 169us/step - loss: 0.6862 - accuracy: 0.5204 - val_loss: 0.7025 - val_accuracy: 0.5486\n",
      "Epoch 57/100\n",
      "957/957 [==============================] - 0s 173us/step - loss: 0.6901 - accuracy: 0.5131 - val_loss: 0.6977 - val_accuracy: 0.5486\n",
      "Epoch 58/100\n",
      "957/957 [==============================] - 0s 172us/step - loss: 0.6908 - accuracy: 0.5246 - val_loss: 0.6970 - val_accuracy: 0.5486\n",
      "Epoch 59/100\n",
      "957/957 [==============================] - 0s 169us/step - loss: 0.6937 - accuracy: 0.5193 - val_loss: 0.6937 - val_accuracy: 0.5486\n",
      "Epoch 60/100\n",
      "957/957 [==============================] - 0s 175us/step - loss: 0.6884 - accuracy: 0.5246 - val_loss: 0.6968 - val_accuracy: 0.5486\n",
      "Epoch 61/100\n",
      "957/957 [==============================] - 0s 178us/step - loss: 0.6862 - accuracy: 0.5319 - val_loss: 0.6996 - val_accuracy: 0.5486\n",
      "Epoch 62/100\n",
      "957/957 [==============================] - 0s 158us/step - loss: 0.6896 - accuracy: 0.5225 - val_loss: 0.6999 - val_accuracy: 0.5486\n",
      "Epoch 63/100\n",
      "957/957 [==============================] - 0s 186us/step - loss: 0.6884 - accuracy: 0.5287 - val_loss: 0.6970 - val_accuracy: 0.5486\n",
      "Epoch 64/100\n",
      "957/957 [==============================] - 0s 169us/step - loss: 0.6870 - accuracy: 0.5235 - val_loss: 0.7019 - val_accuracy: 0.5486\n",
      "Epoch 65/100\n",
      "957/957 [==============================] - 0s 174us/step - loss: 0.6872 - accuracy: 0.5266 - val_loss: 0.7037 - val_accuracy: 0.5486\n",
      "Epoch 66/100\n",
      "957/957 [==============================] - 0s 176us/step - loss: 0.6855 - accuracy: 0.5110 - val_loss: 0.7112 - val_accuracy: 0.5486\n",
      "Epoch 67/100\n",
      "957/957 [==============================] - 0s 167us/step - loss: 0.6903 - accuracy: 0.4869 - val_loss: 0.7040 - val_accuracy: 0.5329\n",
      "Epoch 68/100\n",
      "957/957 [==============================] - 0s 176us/step - loss: 0.6893 - accuracy: 0.5340 - val_loss: 0.7007 - val_accuracy: 0.5486\n",
      "Epoch 69/100\n",
      "957/957 [==============================] - 0s 170us/step - loss: 0.6878 - accuracy: 0.5266 - val_loss: 0.7042 - val_accuracy: 0.5486\n",
      "Epoch 70/100\n",
      "957/957 [==============================] - 0s 174us/step - loss: 0.6882 - accuracy: 0.5225 - val_loss: 0.7028 - val_accuracy: 0.5486\n",
      "Epoch 71/100\n",
      "957/957 [==============================] - 0s 173us/step - loss: 0.6900 - accuracy: 0.5214 - val_loss: 0.6991 - val_accuracy: 0.5486\n",
      "Epoch 72/100\n",
      "957/957 [==============================] - 0s 170us/step - loss: 0.6851 - accuracy: 0.5183 - val_loss: 0.7055 - val_accuracy: 0.5423\n",
      "Epoch 73/100\n",
      "957/957 [==============================] - 0s 172us/step - loss: 0.6894 - accuracy: 0.5319 - val_loss: 0.7040 - val_accuracy: 0.5486\n",
      "Epoch 74/100\n",
      "957/957 [==============================] - 0s 179us/step - loss: 0.6863 - accuracy: 0.5089 - val_loss: 0.7011 - val_accuracy: 0.5486\n",
      "Epoch 75/100\n",
      "957/957 [==============================] - 0s 169us/step - loss: 0.6897 - accuracy: 0.5193 - val_loss: 0.7037 - val_accuracy: 0.5455\n",
      "Epoch 76/100\n",
      "957/957 [==============================] - 0s 174us/step - loss: 0.6850 - accuracy: 0.5329 - val_loss: 0.7025 - val_accuracy: 0.5486\n",
      "Epoch 77/100\n",
      "957/957 [==============================] - 0s 173us/step - loss: 0.6891 - accuracy: 0.5099 - val_loss: 0.7008 - val_accuracy: 0.5486\n",
      "Epoch 78/100\n",
      "957/957 [==============================] - 0s 172us/step - loss: 0.6874 - accuracy: 0.5120 - val_loss: 0.7013 - val_accuracy: 0.5486\n",
      "Epoch 79/100\n",
      "957/957 [==============================] - 0s 169us/step - loss: 0.6868 - accuracy: 0.5225 - val_loss: 0.7018 - val_accuracy: 0.5486\n",
      "Epoch 80/100\n",
      "957/957 [==============================] - 0s 175us/step - loss: 0.6856 - accuracy: 0.5214 - val_loss: 0.7021 - val_accuracy: 0.5423\n",
      "Epoch 81/100\n",
      "957/957 [==============================] - 0s 173us/step - loss: 0.6860 - accuracy: 0.5089 - val_loss: 0.7037 - val_accuracy: 0.5486\n",
      "Epoch 82/100\n",
      "957/957 [==============================] - 0s 171us/step - loss: 0.6857 - accuracy: 0.5225 - val_loss: 0.7082 - val_accuracy: 0.5486\n",
      "Epoch 83/100\n",
      "957/957 [==============================] - 0s 170us/step - loss: 0.6884 - accuracy: 0.5204 - val_loss: 0.7000 - val_accuracy: 0.5486\n",
      "Epoch 84/100\n",
      "957/957 [==============================] - 0s 188us/step - loss: 0.6859 - accuracy: 0.5266 - val_loss: 0.7075 - val_accuracy: 0.5486\n",
      "Epoch 85/100\n",
      "957/957 [==============================] - 0s 173us/step - loss: 0.6854 - accuracy: 0.5266 - val_loss: 0.7057 - val_accuracy: 0.5486\n",
      "Epoch 86/100\n",
      "957/957 [==============================] - 0s 172us/step - loss: 0.6869 - accuracy: 0.5256 - val_loss: 0.7117 - val_accuracy: 0.5486\n",
      "Epoch 87/100\n",
      "957/957 [==============================] - 0s 175us/step - loss: 0.6907 - accuracy: 0.5392 - val_loss: 0.6977 - val_accuracy: 0.5486\n",
      "Epoch 88/100\n",
      "957/957 [==============================] - 0s 187us/step - loss: 0.6865 - accuracy: 0.5183 - val_loss: 0.7001 - val_accuracy: 0.5455\n",
      "Epoch 89/100\n",
      "957/957 [==============================] - 0s 175us/step - loss: 0.6859 - accuracy: 0.5225 - val_loss: 0.7037 - val_accuracy: 0.5361\n",
      "Epoch 90/100\n",
      "957/957 [==============================] - 0s 170us/step - loss: 0.6880 - accuracy: 0.5225 - val_loss: 0.7032 - val_accuracy: 0.5266\n",
      "Epoch 91/100\n",
      "957/957 [==============================] - 0s 178us/step - loss: 0.6900 - accuracy: 0.5152 - val_loss: 0.7018 - val_accuracy: 0.5486\n",
      "Epoch 92/100\n",
      "957/957 [==============================] - 0s 174us/step - loss: 0.6850 - accuracy: 0.5308 - val_loss: 0.7072 - val_accuracy: 0.5455\n",
      "Epoch 93/100\n",
      "957/957 [==============================] - 0s 160us/step - loss: 0.6854 - accuracy: 0.4984 - val_loss: 0.7124 - val_accuracy: 0.5455\n",
      "Epoch 94/100\n",
      "957/957 [==============================] - 0s 180us/step - loss: 0.6897 - accuracy: 0.5329 - val_loss: 0.6994 - val_accuracy: 0.5455\n",
      "Epoch 95/100\n",
      "957/957 [==============================] - 0s 166us/step - loss: 0.6842 - accuracy: 0.5214 - val_loss: 0.7020 - val_accuracy: 0.5486\n",
      "Epoch 96/100\n",
      "957/957 [==============================] - 0s 172us/step - loss: 0.6873 - accuracy: 0.5319 - val_loss: 0.7012 - val_accuracy: 0.5486\n",
      "Epoch 97/100\n",
      "957/957 [==============================] - 0s 175us/step - loss: 0.6859 - accuracy: 0.5131 - val_loss: 0.7029 - val_accuracy: 0.5549\n",
      "Epoch 98/100\n",
      "957/957 [==============================] - 0s 171us/step - loss: 0.6870 - accuracy: 0.5350 - val_loss: 0.7021 - val_accuracy: 0.5235\n",
      "Epoch 99/100\n",
      "957/957 [==============================] - 0s 192us/step - loss: 0.6894 - accuracy: 0.5371 - val_loss: 0.7041 - val_accuracy: 0.5455\n",
      "Epoch 100/100\n",
      "957/957 [==============================] - 0s 192us/step - loss: 0.6872 - accuracy: 0.5361 - val_loss: 0.6974 - val_accuracy: 0.5517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#building and training a model\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, Y, test_size=0.25)\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(5,) ))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
    "                       patience=100, min_delta=0.0001, restore_best_weights = True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data= (X_test,y_test),\n",
    "                              callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 0s 72us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6973692877539273, 0.5517241358757019]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluating the model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM AND GRU METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df1 = copy.deepcopy(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df1 = normalized_df1[['Open','High','Close','Low','Volume','compound_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing function\n",
    "def normalized_df(df):\n",
    "    normalized_df=(df-df.mean())/df.std()\n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for later\n",
    "normalized_df2 = copy.deepcopy(normalized_df1)\n",
    "normalized_df3 = copy.deepcopy(normalized_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>compound_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74.129997</td>\n",
       "      <td>75.160004</td>\n",
       "      <td>74.739998</td>\n",
       "      <td>74.010002</td>\n",
       "      <td>3757800</td>\n",
       "      <td>-0.493900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.330002</td>\n",
       "      <td>76.199997</td>\n",
       "      <td>75.989998</td>\n",
       "      <td>74.849998</td>\n",
       "      <td>4976900</td>\n",
       "      <td>0.074200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75.580002</td>\n",
       "      <td>75.580002</td>\n",
       "      <td>75.070000</td>\n",
       "      <td>74.570000</td>\n",
       "      <td>4051200</td>\n",
       "      <td>0.084700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74.169998</td>\n",
       "      <td>74.730003</td>\n",
       "      <td>73.349998</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>4379000</td>\n",
       "      <td>-0.157993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.620003</td>\n",
       "      <td>73.860001</td>\n",
       "      <td>71.930000</td>\n",
       "      <td>71.790001</td>\n",
       "      <td>5773000</td>\n",
       "      <td>0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>162.419998</td>\n",
       "      <td>164.080002</td>\n",
       "      <td>163.979996</td>\n",
       "      <td>162.380005</td>\n",
       "      <td>3110500</td>\n",
       "      <td>0.055833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>165.000000</td>\n",
       "      <td>167.419998</td>\n",
       "      <td>166.500000</td>\n",
       "      <td>164.869995</td>\n",
       "      <td>4243200</td>\n",
       "      <td>-0.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>165.250000</td>\n",
       "      <td>166.449997</td>\n",
       "      <td>166.229996</td>\n",
       "      <td>164.470001</td>\n",
       "      <td>2689700</td>\n",
       "      <td>0.055833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>166.449997</td>\n",
       "      <td>169.070007</td>\n",
       "      <td>168.029999</td>\n",
       "      <td>166.350006</td>\n",
       "      <td>3765000</td>\n",
       "      <td>-0.361200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>167.699997</td>\n",
       "      <td>168.800003</td>\n",
       "      <td>168.500000</td>\n",
       "      <td>167.220001</td>\n",
       "      <td>2580300</td>\n",
       "      <td>0.055833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1277 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open        High       Close         Low   Volume  compound_mean\n",
       "0      74.129997   75.160004   74.739998   74.010002  3757800      -0.493900\n",
       "1      75.330002   76.199997   75.989998   74.849998  4976900       0.074200\n",
       "2      75.580002   75.580002   75.070000   74.570000  4051200       0.084700\n",
       "3      74.169998   74.730003   73.349998   73.000000  4379000      -0.157993\n",
       "4      73.620003   73.860001   71.930000   71.790001  5773000       0.360000\n",
       "...          ...         ...         ...         ...      ...            ...\n",
       "1272  162.419998  164.080002  163.979996  162.380005  3110500       0.055833\n",
       "1273  165.000000  167.419998  166.500000  164.869995  4243200      -0.273000\n",
       "1274  165.250000  166.449997  166.229996  164.470001  2689700       0.055833\n",
       "1275  166.449997  169.070007  168.029999  166.350006  3765000      -0.361200\n",
       "1276  167.699997  168.800003  168.500000  167.220001  2580300       0.055833\n",
       "\n",
       "[1277 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = normalized_df1.mean(axis = 0)\n",
    "normalized_df1 -= mean\n",
    "std = normalized_df1.std(axis=0)\n",
    "normalized_df1 /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding label: up or down or steady\n",
    "def add_label(df):\n",
    "    idx = len(df.columns)\n",
    "    new_col = np.where(df['Close'] >= df['Close'].shift(1), 1, 0)  \n",
    "    df.insert(loc=idx, column='Label', value=new_col)\n",
    "    df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_label(normalized_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df1 = normalized_df1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.28889326, -1.27782976, -1.26905769, ..., -0.33699085,\n",
       "        -1.92943889,  0.        ],\n",
       "       [-1.24896961, -1.24346657, -1.22752242, ...,  0.13029052,\n",
       "         0.02875619,  1.        ],\n",
       "       [-1.24065222, -1.26395229, -1.25809231, ..., -0.22453055,\n",
       "         0.06494885,  0.        ],\n",
       "       ...,\n",
       "       [ 1.74262958,  1.73855101,  1.77099167, ..., -0.74639388,\n",
       "        -0.03455252,  0.        ],\n",
       "       [ 1.78255296,  1.82512071,  1.83080256, ..., -0.33423109,\n",
       "        -1.47203265,  1.        ],\n",
       "       [ 1.82413991,  1.81619931,  1.84641985, ..., -0.78832693,\n",
       "        -0.03455252,  1.        ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "#defining our generator\n",
    "def generator(data, lookback, delay, min_index, max_index,\n",
    "              shuffle=False, batch_size=32, step=5):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(\n",
    "                min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "        samples = np.zeros((len(rows),\n",
    "                           lookback // step,\n",
    "                           data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][-1]\n",
    "        yield samples, to_categorical(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 30\n",
    "step = 10\n",
    "delay = 1\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train, test and validation set\n",
    "train_gen = generator(normalized_df1,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=0,\n",
    "                      max_index=round(0.6*len(normalized_df1)),\n",
    "                      shuffle=False,\n",
    "                      step=step,\n",
    "                      batch_size=batch_size)\n",
    "val_gen = generator(normalized_df1,\n",
    "                    lookback=lookback,\n",
    "                    delay=delay,\n",
    "                    min_index=round(0.6*len(normalized_df1))+1,\n",
    "                    max_index=round(0.8*len(normalized_df1)),\n",
    "                    step=step,\n",
    "                    batch_size=batch_size)\n",
    "test_gen = generator(normalized_df1,\n",
    "                     lookback=lookback,\n",
    "                     delay=delay,\n",
    "                     min_index=round(0.8*len(normalized_df1))+1,\n",
    "                     max_index=None,\n",
    "                     step=step,\n",
    "                     batch_size=batch_size)\n",
    "\n",
    "val_steps = (round(0.8*len(normalized_df1)) - round(0.6*len(normalized_df1))+1 - lookback) # how many steps to draw from val_gen in order to see the entire validation set\n",
    "test_steps = (len(normalized_df1) - round(0.8*len(normalized_df1))+1 - lookback)\n",
    "# How many steps to draw from test_gen in order to see the entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\48570\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\48570\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 993ms/step - loss: 0.2486 - accuracy: 0.5781 - val_loss: 0.2502 - val_accuracy: 0.4911\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 1s 334ms/step - loss: 0.2450 - accuracy: 0.5469 - val_loss: 0.2477 - val_accuracy: 0.4915\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 1s 322ms/step - loss: 0.2516 - accuracy: 0.4688 - val_loss: 0.2499 - val_accuracy: 0.4641\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 0.2536 - accuracy: 0.3750 - val_loss: 0.2504 - val_accuracy: 0.4860\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 0.2486 - accuracy: 0.5938 - val_loss: 0.2504 - val_accuracy: 0.4827\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 1s 322ms/step - loss: 0.2469 - accuracy: 0.6094 - val_loss: 0.2504 - val_accuracy: 0.4908\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 0.2490 - accuracy: 0.5312 - val_loss: 0.2514 - val_accuracy: 0.4912\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 0.2462 - accuracy: 0.6250 - val_loss: 0.2510 - val_accuracy: 0.4911\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 0.2509 - accuracy: 0.5000 - val_loss: 0.2462 - val_accuracy: 0.4915\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 1s 322ms/step - loss: 0.2490 - accuracy: 0.5625 - val_loss: 0.2500 - val_accuracy: 0.4909\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 1s 319ms/step - loss: 0.2500 - accuracy: 0.5000 - val_loss: 0.2521 - val_accuracy: 0.4904\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 1s 323ms/step - loss: 0.2462 - accuracy: 0.5625 - val_loss: 0.2499 - val_accuracy: 0.4917\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 1s 327ms/step - loss: 0.2456 - accuracy: 0.5469 - val_loss: 0.2507 - val_accuracy: 0.4908\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 1s 324ms/step - loss: 0.2565 - accuracy: 0.4062 - val_loss: 0.2520 - val_accuracy: 0.4912\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 1s 320ms/step - loss: 0.2502 - accuracy: 0.5625 - val_loss: 0.2510 - val_accuracy: 0.4911\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 0.2459 - accuracy: 0.5938 - val_loss: 0.2464 - val_accuracy: 0.4915\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 0.2425 - accuracy: 0.6250 - val_loss: 0.2497 - val_accuracy: 0.4909\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 0.2478 - accuracy: 0.5312 - val_loss: 0.2519 - val_accuracy: 0.4904\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 0.2440 - accuracy: 0.6250 - val_loss: 0.2502 - val_accuracy: 0.4917\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 1s 311ms/step - loss: 0.2510 - accuracy: 0.5000 - val_loss: 0.2509 - val_accuracy: 0.4908\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 1s 320ms/step - loss: 0.2487 - accuracy: 0.5625 - val_loss: 0.2539 - val_accuracy: 0.4912\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 0.2502 - accuracy: 0.5000 - val_loss: 0.2517 - val_accuracy: 0.4911\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 0.2446 - accuracy: 0.5625 - val_loss: 0.2446 - val_accuracy: 0.4915\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 1s 330ms/step - loss: 0.2435 - accuracy: 0.5469 - val_loss: 0.2495 - val_accuracy: 0.4909\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 1s 320ms/step - loss: 0.2593 - accuracy: 0.4062 - val_loss: 0.2523 - val_accuracy: 0.4860\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 1s 320ms/step - loss: 0.2489 - accuracy: 0.5312 - val_loss: 0.2509 - val_accuracy: 0.4872\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 1s 329ms/step - loss: 0.2456 - accuracy: 0.5781 - val_loss: 0.2517 - val_accuracy: 0.4908\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 0.2396 - accuracy: 0.6250 - val_loss: 0.2538 - val_accuracy: 0.4868\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 1s 324ms/step - loss: 0.2475 - accuracy: 0.5312 - val_loss: 0.2515 - val_accuracy: 0.4865\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 1s 320ms/step - loss: 0.2434 - accuracy: 0.6250 - val_loss: 0.2438 - val_accuracy: 0.4871\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 1s 324ms/step - loss: 0.2514 - accuracy: 0.5000 - val_loss: 0.2493 - val_accuracy: 0.4909\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 1s 324ms/step - loss: 0.2488 - accuracy: 0.5625 - val_loss: 0.2536 - val_accuracy: 0.4904\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 0.2498 - accuracy: 0.5000 - val_loss: 0.2512 - val_accuracy: 0.4917\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 1s 329ms/step - loss: 0.2447 - accuracy: 0.5625 - val_loss: 0.2518 - val_accuracy: 0.4908\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 1s 334ms/step - loss: 0.2417 - accuracy: 0.5469 - val_loss: 0.2551 - val_accuracy: 0.4868\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 1s 323ms/step - loss: 0.2557 - accuracy: 0.4531 - val_loss: 0.2524 - val_accuracy: 0.4864\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 1s 319ms/step - loss: 0.2489 - accuracy: 0.5781 - val_loss: 0.2440 - val_accuracy: 0.4871\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 0.2427 - accuracy: 0.6094 - val_loss: 0.2487 - val_accuracy: 0.4953\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 0.2373 - accuracy: 0.5938 - val_loss: 0.2541 - val_accuracy: 0.4993\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 0.2481 - accuracy: 0.5781 - val_loss: 0.2527 - val_accuracy: 0.4873\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 1s 323ms/step - loss: 0.2423 - accuracy: 0.6406 - val_loss: 0.2528 - val_accuracy: 0.4908\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 0.2517 - accuracy: 0.4531 - val_loss: 0.2564 - val_accuracy: 0.4868\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 1s 322ms/step - loss: 0.2494 - accuracy: 0.5312 - val_loss: 0.2534 - val_accuracy: 0.4865\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 1s 319ms/step - loss: 0.2496 - accuracy: 0.5000 - val_loss: 0.2421 - val_accuracy: 0.4916\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 1s 319ms/step - loss: 0.2446 - accuracy: 0.5938 - val_loss: 0.2487 - val_accuracy: 0.4908\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 0.2428 - accuracy: 0.5625 - val_loss: 0.2549 - val_accuracy: 0.4948\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 0.2480 - accuracy: 0.5469 - val_loss: 0.2533 - val_accuracy: 0.4873\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 1s 319ms/step - loss: 0.2558 - accuracy: 0.4219 - val_loss: 0.2535 - val_accuracy: 0.4908\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 0.2378 - accuracy: 0.6250 - val_loss: 0.2570 - val_accuracy: 0.4869\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 0.2365 - accuracy: 0.5781 - val_loss: 0.2535 - val_accuracy: 0.4909\n"
     ]
    }
   ],
   "source": [
    "#Building and training LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, return_sequences=True,\n",
    "                    input_shape=(None, normalized_df1.shape[-1]),\n",
    "                    kernel_initializer='random_uniform'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(60, dropout=0.0, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.compile(loss='mean_squared_error', optimizer=RMSprop(),metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
    "                       patience=100, min_delta=0.0001, restore_best_weights = True)\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=2,\n",
    "                              epochs=50,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps,\n",
    "                              callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`steps=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps` or use the `keras.utils.Sequence` class.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-f354348ab393>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test acc:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_loss:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1789\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1790\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1791\u001b[1;33m             verbose=verbose)\n\u001b[0m\u001b[0;32m   1792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1793\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(model, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             raise ValueError('`steps=None` is only valid for a generator'\n\u001b[0m\u001b[0;32m    322\u001b[0m                              \u001b[1;34m' based on the `keras.utils.Sequence` class.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                              \u001b[1;34m' Please specify `steps` or use the'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `steps=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps` or use the `keras.utils.Sequence` class."
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(test_gen, steps=5)\n",
    "print('test acc:', test_acc)\n",
    "print(\"test_loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.5546875\n",
      "test_loss: 0.247816264629364\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(test_gen, steps=4)\n",
    "print('test acc:', test_acc)\n",
    "print(\"test_loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building and training a model with GRU\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32,\n",
    "                     dropout=0.3,\n",
    "                     recurrent_dropout=0.2,\n",
    "                     return_sequences=True,\n",
    "                     input_shape=(None, normalized_df1.shape[-1])))\n",
    "model.add(layers.GRU(64, activation='relu',\n",
    "                     dropout=0.3,\n",
    "                     recurrent_dropout=0.1))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.compile(optimizer=RMSprop(), loss='mean_squared_error', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
    "                       patience=50, min_delta=0.0001, restore_best_weights = True)\n",
    "    \n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=2,\n",
    "                              epochs=250,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps,\n",
    "                              callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the model\n",
    "test_loss, test_acc = model.evaluate_generator(test_gen, steps=3)\n",
    "print('test acc:', test_acc)\n",
    "print(\"test_loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing data\n",
    "normalized_df1 = normalized_df2\n",
    "\n",
    "mean = normalized_df1.mean(axis = 0)\n",
    "normalized_df1 -= mean\n",
    "std = normalized_df1.std(axis=0)\n",
    "normalized_df1 /= std\n",
    "#adding label: up/down or steady\n",
    "def add_label(df):\n",
    "    idx = len(df.columns)\n",
    "    new_col = np.where(df['Close'] >= df['Close'].shift(1), 1, 0)  \n",
    "    df.insert(loc=idx, column='Label', value=new_col)\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "add_label(normalized_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying function \n",
    "del normalized_df1['compound_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df1 = normalized_df1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into tain validation and test set\n",
    "train_gen = generator(normalized_df1,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=0,\n",
    "                      max_index=round(0.6*len(normalized_df1)),\n",
    "                      shuffle=False,\n",
    "                      step=step,\n",
    "                      batch_size=batch_size)\n",
    "val_gen = generator(normalized_df1,\n",
    "                    lookback=lookback,\n",
    "                    delay=delay,\n",
    "                    min_index=round(0.6*len(normalized_df1))+1,\n",
    "                    max_index=round(0.8*len(normalized_df1)),\n",
    "                    step=step,\n",
    "                    batch_size=batch_size)\n",
    "test_gen = generator(normalized_df1,\n",
    "                     lookback=lookback,\n",
    "                     delay=delay,\n",
    "                     min_index=round(0.8*len(normalized_df1))+1,\n",
    "                     max_index=None,\n",
    "                     step=step,\n",
    "                     batch_size=batch_size)\n",
    "\n",
    "val_steps = (round(0.8*len(normalized_df1)) - round(0.6*len(normalized_df1))+1 - lookback) # how many steps to draw from val_gen in order to see the entire validation set\n",
    "test_steps = (len(normalized_df1) - round(0.8*len(normalized_df1))+1 - lookback)\n",
    "# How many steps to draw from test_gen in order to see the entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bilding and training LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, return_sequences=True,\n",
    "                    input_shape=(None, normalized_df1.shape[-1]),\n",
    "                    kernel_initializer='random_uniform'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(60, dropout=0.0, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.compile(loss='mean_squared_error', optimizer=RMSprop(),metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
    "                       patience=50, min_delta=0.0001, restore_best_weights = True)\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=2,\n",
    "                              epochs=200,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps,\n",
    "                              callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating the model\n",
    "test_loss, test_acc = model.evaluate_generator(test_gen, steps=4)\n",
    "print('test acc:', test_acc)\n",
    "print(\"test_loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bilding and training GRU model\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32,\n",
    "                     dropout=0.3,\n",
    "                     recurrent_dropout=0.2,\n",
    "                     return_sequences=True,\n",
    "                     input_shape=(None, normalized_df1.shape[-1])))\n",
    "model.add(layers.GRU(64, activation='relu',\n",
    "                     dropout=0.3,\n",
    "                     recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.compile(optimizer=RMSprop(), loss='mean_squared_error', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
    "                       patience=100, min_delta=0.0001, restore_best_weights = True)\n",
    "    \n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=2,\n",
    "                              epochs=500,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps,\n",
    "                              callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating the model\n",
    "test_loss, test_acc = model.evaluate_generator(test_gen, steps=4)\n",
    "print('test acc:', test_acc)\n",
    "print(\"test_loss:\", test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
